{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b295d34-c8b3-4ef3-a669-840153be527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 20:59:30.148999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import jax\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from flax.metrics import tensorboard\n",
    "import jax.numpy as jnp\n",
    "from flax.training import train_state, orbax_utils\n",
    "import orbax.checkpoint\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import sys\n",
    "sys.argv = ['']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828ba16-17d4-49bc-822c-f084ed27a984",
   "metadata": {},
   "source": [
    "#### Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088c0763-dae0-454c-b8df-02405d146ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--test_ratio', default=0.2, type=float,\n",
    "                    help='Test ratio for splitting the dataset')\n",
    "parser.add_argument('--batch_size', default=64, type=int,\n",
    "                    help='Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus')\n",
    "parser.add_argument('--epochs', default=400, type=int)\n",
    "parser.add_argument('--accum_iter', default=1, type=int,\n",
    "                    help='Accumulate gradient iterations (for increasing the effective batch size under memory constraints)')\n",
    "\n",
    "# model parameters\n",
    "parser.add_argument('--input_size', default=224, type=int,\n",
    "                    help='images input size')\n",
    "parser.add_argument('--n_input_vars', default=3, type=int,\n",
    "                    help='images input size')\n",
    "\n",
    "# optimizer parameters\n",
    "parser.add_argument('--weight_decay', type=float, default=0.05,\n",
    "                    help='weight decay (default: 0.05)')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-3, metavar='LR',\n",
    "                    help='learning rate (absolute lr)')\n",
    "parser.add_argument('--blr', type=float, default=1e-3, metavar='LR',\n",
    "                    help='base learning rate: absolute_lr = base_lr * total_batch_size / 256')\n",
    "parser.add_argument('--min_lr', type=float, default=0., metavar='LR',\n",
    "                    help='lower lr bound for cyclic schedulers that hit 0')\n",
    "\n",
    "parser.add_argument('--warmup_epochs', type=int, default=40, metavar='N',\n",
    "                    help='epochs to warmup LR')\n",
    "\n",
    "# dataset parameters\n",
    "parser.add_argument('--purple_air_dir', default='../../NASA_Citizen_Science/data/PurpleAir/SF', type=str,\n",
    "                    help='pa dataset path')\n",
    "\n",
    "parser.add_argument('--air_now_dir', default='../../NASA_Citizen_Science/data/airNow/stations', type=str,\n",
    "                    help='AirNow dataset path')\n",
    "\n",
    "parser.add_argument('--pair_file', default='../../NASA_Citizen_Science/metrics/min_great_circle_df.csv', type=str,\n",
    "                    help='Distance file path')\n",
    "\n",
    "parser.add_argument('--output_dir', default='./output_dir',\n",
    "                    help='path where to save, empty for no saving')\n",
    "parser.add_argument('--log_dir', default='./output_dir',\n",
    "                    help='path where to tensorboard log')\n",
    "parser.add_argument('--device', default='cuda',\n",
    "                    help='device to use for training / testing')\n",
    "parser.add_argument('--seed', default=0, type=int)\n",
    "parser.add_argument('--resume', default='',\n",
    "                    help='resume from checkpoint')\n",
    "\n",
    "parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                    help='start epoch')\n",
    "parser.add_argument('--num_workers', default=10, type=int)\n",
    "parser.add_argument('--pin_mem', action='store_true',\n",
    "                    help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "parser.add_argument('--no_pin_mem', action='store_false', dest='pin_mem')\n",
    "parser.set_defaults(pin_mem=True)\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c638d84-b362-4d68-8637-df1041a91f8b",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5deed577-1ca5-4981-883b-52294abf2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path \n",
    "from os.path import isfile\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple,list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "class LCSFEM_Bias_Dataset(Dataset):\n",
    "    def __init__(self, pair_file, pa_dir, an_dir, transform=None, target_transform=None, ln_scale = False):\n",
    "        an_dir = Path(an_dir)\n",
    "        pa_dir = Path(pa_dir)\n",
    "        self.data = self.load_file(pair_file, pa_dir, an_dir)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.ln_scale = ln_scale\n",
    "        \n",
    "        self.an_dir = Path(an_dir)\n",
    "        self.pa_dir = Path(pa_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx][-4:-1].values\n",
    "        label = self.data.iloc[idx][-1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        if self.ln_scale:\n",
    "            label = jnp.log(label)\n",
    "        return sample.astype(float), label.astype(float)\n",
    "    \n",
    "    def load_file(self, pair_file, pa_dir, an_dir, pair_dis = 1):\n",
    "        train_data = pd.DataFrame()\n",
    "        min_df = pd.read_csv(pair_file, index_col = 0)\n",
    "        subtracted = min_df[min_df['1']< pair_dis]\n",
    "        for i, row in subtracted.iterrows():\n",
    "            pa_name = i\n",
    "            if (isfile(pa_dir/ pa_name)):\n",
    "                pa_data = pd.read_csv(pa_dir/ pa_name, index_col=0)\n",
    "                pa_data['datetime'] = pd.to_datetime(pa_data['datetime'])\n",
    "                pa_data.index = pa_data['datetime']\n",
    "                pa_data.drop(['label'], axis=1, inplace=True) # remove label column\n",
    "                pa_data = pa_data.resample('H').mean().dropna()\n",
    "                pa_data['PM25'] = pa_data.loc[:, ['pm25_A', 'pm25_B']].mean(axis=1)\n",
    "                pa_data = pa_data[pa_data['PM25'] <= 200]\n",
    "\n",
    "                an_data = pd.read_csv(an_dir / row[\"0\"], index_col = 0)\n",
    "                an_data.index = pd.to_datetime(an_data['datetime'])\n",
    "                an_data = an_data[an_data['concentration'] > 0]\n",
    "                \n",
    "                sub_data = pa_data[pa_data.index.isin(an_data.index)].copy()\n",
    "                sub_data['an'] = an_data[an_data.index.isin(pa_data.index)]['concentration'].values\n",
    "                \n",
    "                train_data = pd.concat([train_data, sub_data])\n",
    "\n",
    "        return train_data\n",
    "       \n",
    "\n",
    "class NumpyLoader(DataLoader):\n",
    "  def __init__(self, dataset, batch_size=1,\n",
    "                shuffle=False, sampler=None,\n",
    "                batch_sampler=None, num_workers=0,\n",
    "                pin_memory=False, drop_last=False,\n",
    "                timeout=0, worker_init_fn=None):\n",
    "    super(self.__class__, self).__init__(dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9c393-bd77-4bd8-8707-1f1d00852fb9",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1891680-c17f-4e68-a466-74793cd7e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable, Sequence\n",
    "class MLP(nn.Module):\n",
    "  features: Sequence[int]\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    for feat in self.features[:-1]:\n",
    "      x = nn.relu(nn.Dense(feat)(x))\n",
    "    x = nn.Dense(self.features[-1])(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee32ea-1dc0-4b94-a3ba-52ad10f2d659",
   "metadata": {},
   "source": [
    "#### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2d9a57-3bb4-493f-b91e-eb1725627585",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def mse_loss(preds, targets):\n",
    "  return jnp.mean((preds.flatten() - targets)**2)\n",
    "\n",
    "@jax.jit\n",
    "def apply_model(state, x, y):\n",
    "    def loss_fn(params):\n",
    "        y_hat = state.apply_fn({'params': params}, x)         # make forward pass\n",
    "        loss = mse_loss(y_hat, y).mean()\n",
    "        return loss, y_hat\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, y_hat), grads = grad_fn(state.params)\n",
    "    return state, loss, grads\n",
    "\n",
    "def train_one_epoch(state, training_generator):\n",
    "    train_loss = []\n",
    "    for i, (x, y) in enumerate(training_generator):\n",
    "        state, loss, grads = apply_model(state, x, y)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        state = state.apply_gradients(grads=grads)\n",
    "    train_loss = jnp.mean(jnp.array(train_loss))\n",
    "    return state, train_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d7630-ec5e-400f-8e85-f836bcdb0902",
   "metadata": {},
   "source": [
    "#### Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2c0bdf8-4a1e-417c-a137-2facea561da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.vmap\n",
    "def mse_loss(preds, targets):\n",
    "  return jnp.mean((preds.flatten() - targets)**2)\n",
    "\n",
    "def eval(state, testing_generator):\n",
    "    eval_loss = []\n",
    "    for i, (x,y) in enumerate(testing_generator):\n",
    "        # variables = model.init(rng, x)\n",
    "        def loss_fn(params):\n",
    "            # make forward pass\n",
    "            y_hat = state.apply_fn({'params': params}, x)\n",
    "\n",
    "            loss = mse_loss(y_hat, y).mean()\n",
    "            eval_loss.append(loss.primal.item())\n",
    "            return loss\n",
    "        grads = jax.grad(loss_fn)(state.params)\n",
    "        # eval_loss.append(grads)\n",
    "    eval_loss = jnp.mean(jnp.array(eval_loss))\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e4e2a23-98b3-44db-af12-99438b45c178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82954 20738\n",
      "103692\n",
      "Epoch: 0, train_loss: 1735290368.0000, eval_loss: 6817127936.0000\n",
      "Epoch: 1, train_loss: 2883278848.0000, eval_loss: 21357.5176\n",
      "Epoch: 2, train_loss: 117787.3125, eval_loss: 4593.3481\n",
      "Epoch: 3, train_loss: 1791952.6250, eval_loss: 19546924.0000\n",
      "Epoch: 4, train_loss: 33901232.0000, eval_loss: 31.6151\n",
      "Epoch: 5, train_loss: 32.4443, eval_loss: 51.1328\n",
      "Epoch: 6, train_loss: 2102.4893, eval_loss: 44250.7617\n",
      "Epoch: 7, train_loss: 22171316.0000, eval_loss: 25.9926\n",
      "Epoch: 8, train_loss: 26.5348, eval_loss: 25.8738\n",
      "Epoch: 9, train_loss: 26.3618, eval_loss: 25.6470\n",
      "Epoch: 10, train_loss: 26.0416, eval_loss: 25.2281\n",
      "Epoch: 11, train_loss: 25.4682, eval_loss: 24.4928\n",
      "Epoch: 12, train_loss: 24.4748, eval_loss: 23.2540\n",
      "Epoch: 13, train_loss: 22.8574, eval_loss: 21.3071\n",
      "Epoch: 14, train_loss: 20.4660, eval_loss: 18.6506\n",
      "Epoch: 15, train_loss: 17.7099, eval_loss: 16.2612\n",
      "Epoch: 16, train_loss: 15.8131, eval_loss: 15.0506\n",
      "Epoch: 17, train_loss: 14.7639, eval_loss: 14.1590\n",
      "Epoch: 18, train_loss: 14.0433, eval_loss: 13.5745\n",
      "Epoch: 19, train_loss: 13.7117, eval_loss: 13.3790\n",
      "Epoch: 20, train_loss: 13.5893, eval_loss: 13.2768\n",
      "Epoch: 21, train_loss: 13.5274, eval_loss: 13.2032\n",
      "Epoch: 22, train_loss: 13.4930, eval_loss: 13.1528\n",
      "Epoch: 23, train_loss: 13.4619, eval_loss: 13.1011\n",
      "Epoch: 24, train_loss: 13.4304, eval_loss: 13.0290\n",
      "Epoch: 25, train_loss: 13.3992, eval_loss: 2442.7539\n",
      "Epoch: 26, train_loss: 9628425.0000, eval_loss: 17.8438\n",
      "Epoch: 27, train_loss: 111394.5781, eval_loss: 16.1037\n",
      "Epoch: 28, train_loss: 57.5916, eval_loss: 16.8529\n",
      "Epoch: 29, train_loss: 17.1603, eval_loss: 15.8160\n",
      "Epoch: 30, train_loss: 16.4181, eval_loss: 15.3734\n",
      "Epoch: 31, train_loss: 16.0538, eval_loss: 15.0179\n",
      "Epoch: 32, train_loss: 15.7576, eval_loss: 14.7711\n",
      "Epoch: 33, train_loss: 15.5135, eval_loss: 14.5485\n",
      "Epoch: 34, train_loss: 15.2758, eval_loss: 14.3432\n",
      "Epoch: 35, train_loss: 14.9248, eval_loss: 13.8463\n",
      "Epoch: 36, train_loss: 14.3344, eval_loss: 13.2436\n",
      "Epoch: 37, train_loss: 13.8723, eval_loss: 13.0434\n",
      "Epoch: 38, train_loss: 13.6412, eval_loss: 12.9305\n",
      "Epoch: 39, train_loss: 13.5195, eval_loss: 12.9613\n",
      "Epoch: 40, train_loss: 13.4272, eval_loss: 12.7498\n",
      "Epoch: 41, train_loss: 13.3579, eval_loss: 12.7890\n",
      "Epoch: 42, train_loss: 13.3886, eval_loss: 12.8322\n",
      "Epoch: 43, train_loss: 529471.0625, eval_loss: 12.8143\n",
      "Epoch: 44, train_loss: 13.4216, eval_loss: 12.8012\n",
      "Epoch: 45, train_loss: 13.4820, eval_loss: 12.7924\n",
      "Epoch: 46, train_loss: 13.6118, eval_loss: 12.8019\n",
      "Epoch: 47, train_loss: 1854700.7500, eval_loss: 12.9677\n",
      "Epoch: 48, train_loss: 13.5997, eval_loss: 12.8920\n",
      "Epoch: 49, train_loss: 13.6333, eval_loss: 13.6502\n",
      "Epoch: 50, train_loss: 13.7211, eval_loss: 12.8428\n",
      "Epoch: 51, train_loss: 13.4688, eval_loss: 12.7301\n",
      "Epoch: 52, train_loss: 13.4275, eval_loss: 12.6854\n",
      "Epoch: 53, train_loss: 14.1729, eval_loss: 12.9465\n",
      "Epoch: 54, train_loss: 13.5429, eval_loss: 12.8372\n",
      "Epoch: 55, train_loss: 13.4710, eval_loss: 12.7812\n",
      "Epoch: 56, train_loss: 13.4256, eval_loss: 12.7432\n",
      "Epoch: 57, train_loss: 13.3875, eval_loss: 12.6974\n",
      "Epoch: 58, train_loss: 13.3503, eval_loss: 12.6751\n",
      "Epoch: 59, train_loss: 13.3017, eval_loss: 12.6678\n",
      "Epoch: 60, train_loss: 13.2984, eval_loss: 12.6745\n",
      "Epoch: 61, train_loss: 13.2719, eval_loss: 12.6770\n",
      "Epoch: 62, train_loss: 13.3054, eval_loss: 12.6769\n",
      "Epoch: 63, train_loss: 13.2556, eval_loss: 12.6906\n",
      "Epoch: 64, train_loss: 13.2888, eval_loss: 12.6692\n",
      "Epoch: 65, train_loss: 13.2327, eval_loss: 12.6956\n",
      "Epoch: 66, train_loss: 13.2470, eval_loss: 12.6936\n",
      "Epoch: 67, train_loss: 13.2541, eval_loss: 12.7011\n",
      "Epoch: 68, train_loss: 13.3205, eval_loss: 12.6941\n",
      "Epoch: 69, train_loss: 13.3258, eval_loss: 12.7306\n",
      "Epoch: 70, train_loss: 13.3824, eval_loss: 12.7435\n",
      "Epoch: 71, train_loss: 13.3900, eval_loss: 12.7703\n",
      "Epoch: 72, train_loss: 13.4269, eval_loss: 12.8547\n",
      "Epoch: 73, train_loss: 13.4884, eval_loss: 13.5639\n",
      "Epoch: 74, train_loss: 13.4338, eval_loss: 12.9161\n",
      "Epoch: 75, train_loss: 1266.9868, eval_loss: 64285888.0000\n",
      "Epoch: 76, train_loss: 5135500.0000, eval_loss: 5548.1821\n",
      "Epoch: 77, train_loss: 3101.7119, eval_loss: 63.5535\n",
      "Epoch: 78, train_loss: 14223.5830, eval_loss: 267.0015\n",
      "Epoch: 79, train_loss: 557.6301, eval_loss: 15.3742\n",
      "Epoch: 80, train_loss: 100.6501, eval_loss: 12.8049\n",
      "Epoch: 81, train_loss: 13.3721, eval_loss: 12.7988\n",
      "Epoch: 82, train_loss: 1368.7623, eval_loss: 12.7548\n",
      "Epoch: 83, train_loss: 13.3056, eval_loss: 12.7397\n",
      "Epoch: 84, train_loss: 13.2972, eval_loss: 12.7385\n",
      "Epoch: 85, train_loss: 13.3055, eval_loss: 12.6401\n",
      "Epoch: 86, train_loss: 13.2701, eval_loss: 12.7234\n",
      "Epoch: 87, train_loss: 13.2950, eval_loss: 12.7548\n",
      "Epoch: 88, train_loss: 13.3073, eval_loss: 12.6470\n",
      "Epoch: 89, train_loss: 13.2506, eval_loss: 12.7052\n",
      "Epoch: 90, train_loss: 13.2581, eval_loss: 12.6923\n",
      "Epoch: 91, train_loss: 13.2982, eval_loss: 12.6310\n",
      "Epoch: 92, train_loss: 13.2584, eval_loss: 12.7112\n",
      "Epoch: 93, train_loss: 13.2690, eval_loss: 12.7179\n",
      "Epoch: 94, train_loss: 13.3203, eval_loss: 12.6273\n",
      "Epoch: 95, train_loss: 13.2856, eval_loss: 12.7127\n",
      "Epoch: 96, train_loss: 13.3108, eval_loss: 12.7441\n",
      "Epoch: 97, train_loss: 13.3167, eval_loss: 12.8200\n",
      "Epoch: 98, train_loss: 13.3226, eval_loss: 12.6470\n",
      "Epoch: 99, train_loss: 13.3477, eval_loss: 12.7834\n",
      "Epoch: 100, train_loss: 16.5704, eval_loss: 12.9293\n",
      "Epoch: 101, train_loss: 13.3777, eval_loss: 12.8926\n",
      "Epoch: 102, train_loss: 13.3669, eval_loss: 12.8197\n",
      "Epoch: 103, train_loss: 13.3716, eval_loss: 12.8180\n",
      "Epoch: 104, train_loss: 13.4655, eval_loss: 12.7134\n",
      "Epoch: 105, train_loss: 13.4159, eval_loss: 12.8892\n",
      "Epoch: 106, train_loss: 13.3058, eval_loss: 12.8084\n",
      "Epoch: 107, train_loss: 13.3322, eval_loss: 12.9872\n",
      "Epoch: 108, train_loss: 53483.5156, eval_loss: 12.7323\n",
      "Epoch: 109, train_loss: 13.3521, eval_loss: 12.7791\n",
      "Epoch: 110, train_loss: 13.3565, eval_loss: 12.8185\n",
      "Epoch: 111, train_loss: 13.3554, eval_loss: 12.7577\n",
      "Epoch: 112, train_loss: 13.4513, eval_loss: 12.7104\n",
      "Epoch: 113, train_loss: 13.3494, eval_loss: 12.7974\n",
      "Epoch: 114, train_loss: 13.3914, eval_loss: 12.7586\n",
      "Epoch: 115, train_loss: 13.3134, eval_loss: 12.7478\n",
      "Epoch: 116, train_loss: 13.3028, eval_loss: 12.7190\n",
      "Epoch: 117, train_loss: 13.3015, eval_loss: 12.8014\n",
      "Epoch: 118, train_loss: 13.3549, eval_loss: 12.8421\n",
      "Epoch: 119, train_loss: 13.3569, eval_loss: 12.7066\n",
      "Epoch: 120, train_loss: 13.3310, eval_loss: 12.8479\n",
      "Epoch: 121, train_loss: 13.3854, eval_loss: 12.7169\n",
      "Epoch: 122, train_loss: 13.4596, eval_loss: 12.8345\n",
      "Epoch: 123, train_loss: 13.4754, eval_loss: 12.8642\n",
      "Epoch: 124, train_loss: 13.4035, eval_loss: 12.8334\n",
      "Epoch: 125, train_loss: 13.3994, eval_loss: 12.8671\n",
      "Epoch: 126, train_loss: 13.3877, eval_loss: 12.8675\n",
      "Epoch: 127, train_loss: 13.3875, eval_loss: 12.8710\n",
      "Epoch: 128, train_loss: 13.3937, eval_loss: 12.8347\n",
      "Epoch: 129, train_loss: 13.3931, eval_loss: 12.8812\n",
      "Epoch: 130, train_loss: 13.3884, eval_loss: 12.8960\n",
      "Epoch: 131, train_loss: 13.4325, eval_loss: 12.8807\n",
      "Epoch: 132, train_loss: 13.4426, eval_loss: 12.8836\n",
      "Epoch: 133, train_loss: 13.3928, eval_loss: 12.8742\n",
      "Epoch: 134, train_loss: 13.3712, eval_loss: 12.8264\n",
      "Epoch: 135, train_loss: 13.3528, eval_loss: 12.8188\n",
      "Epoch: 136, train_loss: 13.3508, eval_loss: 12.8156\n",
      "Epoch: 137, train_loss: 13.3149, eval_loss: 12.8013\n",
      "Epoch: 138, train_loss: 13.3359, eval_loss: 12.5977\n",
      "Epoch: 139, train_loss: 13.4180, eval_loss: 12.6092\n",
      "Epoch: 140, train_loss: 13.3505, eval_loss: 12.6176\n",
      "Epoch: 141, train_loss: 13.3589, eval_loss: 12.6632\n",
      "Epoch: 142, train_loss: 13.3357, eval_loss: 12.6580\n",
      "Epoch: 143, train_loss: 13.3640, eval_loss: 12.6568\n",
      "Epoch: 144, train_loss: 13.3339, eval_loss: 12.7083\n",
      "Epoch: 145, train_loss: 13.3299, eval_loss: 12.7249\n",
      "Epoch: 146, train_loss: 13.3389, eval_loss: 12.6931\n",
      "Epoch: 147, train_loss: 13.6354, eval_loss: 12.7708\n",
      "Epoch: 148, train_loss: 13.5884, eval_loss: 12.6280\n",
      "Epoch: 149, train_loss: 13.3825, eval_loss: 12.6842\n",
      "Epoch: 150, train_loss: 13.3367, eval_loss: 12.6720\n",
      "Epoch: 151, train_loss: 13.3182, eval_loss: 12.7053\n",
      "Epoch: 152, train_loss: 13.2916, eval_loss: 12.6087\n",
      "Epoch: 153, train_loss: 13.3090, eval_loss: 12.6637\n",
      "Epoch: 154, train_loss: 13.3401, eval_loss: 12.6675\n",
      "Epoch: 155, train_loss: 13.2975, eval_loss: 12.7835\n",
      "Epoch: 156, train_loss: 13.2918, eval_loss: 12.6815\n",
      "Epoch: 157, train_loss: 13.3058, eval_loss: 12.7308\n",
      "Epoch: 158, train_loss: 13.3028, eval_loss: 12.5814\n",
      "Epoch: 159, train_loss: 13.3084, eval_loss: 12.5953\n",
      "Epoch: 160, train_loss: 13.2972, eval_loss: 13.0641\n",
      "Epoch: 161, train_loss: 13.3532, eval_loss: 12.6526\n",
      "Epoch: 162, train_loss: 13.2913, eval_loss: 12.6378\n",
      "Epoch: 163, train_loss: 13.2908, eval_loss: 12.6346\n",
      "Epoch: 164, train_loss: 13.2708, eval_loss: 12.6417\n",
      "Epoch: 165, train_loss: 13.3028, eval_loss: 12.5904\n",
      "Epoch: 166, train_loss: 13.3289, eval_loss: 12.6058\n",
      "Epoch: 167, train_loss: 13.2654, eval_loss: 12.6325\n",
      "Epoch: 168, train_loss: 13.3277, eval_loss: 12.6801\n",
      "Epoch: 169, train_loss: 13.2459, eval_loss: 12.6796\n",
      "Epoch: 170, train_loss: 13.2754, eval_loss: 12.6815\n",
      "Epoch: 171, train_loss: 13.3426, eval_loss: 12.6189\n",
      "Epoch: 172, train_loss: 13.2605, eval_loss: 12.7214\n",
      "Epoch: 173, train_loss: 13.2456, eval_loss: 12.6150\n",
      "Epoch: 174, train_loss: 13.2776, eval_loss: 12.6462\n",
      "Epoch: 175, train_loss: 13.2623, eval_loss: 12.6678\n",
      "Epoch: 176, train_loss: 13.2541, eval_loss: 12.6850\n",
      "Epoch: 177, train_loss: 13.2911, eval_loss: 12.6526\n",
      "Epoch: 178, train_loss: 13.2294, eval_loss: 12.6770\n",
      "Epoch: 179, train_loss: 13.2590, eval_loss: 12.6453\n",
      "Epoch: 180, train_loss: 13.2888, eval_loss: 12.6557\n",
      "Epoch: 181, train_loss: 13.2556, eval_loss: 12.5899\n",
      "Epoch: 182, train_loss: 13.2696, eval_loss: 12.7262\n",
      "Epoch: 183, train_loss: 13.2619, eval_loss: 12.6128\n",
      "Epoch: 184, train_loss: 13.2604, eval_loss: 12.5844\n",
      "Epoch: 185, train_loss: 13.2423, eval_loss: 12.6293\n",
      "Epoch: 186, train_loss: 13.2554, eval_loss: 12.6204\n",
      "Epoch: 187, train_loss: 13.2348, eval_loss: 12.5647\n",
      "Epoch: 188, train_loss: 13.2649, eval_loss: 12.6069\n",
      "Epoch: 189, train_loss: 13.2869, eval_loss: 12.5966\n",
      "Epoch: 190, train_loss: 13.2432, eval_loss: 12.5918\n",
      "Epoch: 191, train_loss: 13.2129, eval_loss: 12.6165\n",
      "Epoch: 192, train_loss: 13.2794, eval_loss: 12.5737\n",
      "Epoch: 193, train_loss: 13.2312, eval_loss: 12.6051\n",
      "Epoch: 194, train_loss: 13.2388, eval_loss: 12.5867\n",
      "Epoch: 195, train_loss: 13.2276, eval_loss: 12.5720\n",
      "Epoch: 196, train_loss: 13.2466, eval_loss: 12.5439\n",
      "Epoch: 197, train_loss: 13.2146, eval_loss: 12.5768\n",
      "Epoch: 198, train_loss: 13.2173, eval_loss: 12.5778\n",
      "Epoch: 199, train_loss: 13.2292, eval_loss: 12.5893\n",
      "Epoch: 200, train_loss: 13.2198, eval_loss: 12.5646\n",
      "Epoch: 201, train_loss: 13.2154, eval_loss: 12.5561\n",
      "Epoch: 202, train_loss: 13.2241, eval_loss: 12.5725\n",
      "Epoch: 203, train_loss: 13.2165, eval_loss: 12.6038\n",
      "Epoch: 204, train_loss: 13.1922, eval_loss: 12.5447\n",
      "Epoch: 205, train_loss: 13.2378, eval_loss: 12.5503\n",
      "Epoch: 206, train_loss: 13.2059, eval_loss: 12.5503\n",
      "Epoch: 207, train_loss: 13.2112, eval_loss: 12.5441\n",
      "Epoch: 208, train_loss: 13.2005, eval_loss: 12.5500\n",
      "Epoch: 209, train_loss: 13.2128, eval_loss: 12.5607\n",
      "Epoch: 210, train_loss: 13.2244, eval_loss: 12.6057\n",
      "Epoch: 211, train_loss: 13.2134, eval_loss: 12.5361\n",
      "Epoch: 212, train_loss: 13.2075, eval_loss: 12.5492\n",
      "Epoch: 213, train_loss: 13.2005, eval_loss: 12.5988\n",
      "Epoch: 214, train_loss: 13.2248, eval_loss: 12.5708\n",
      "Epoch: 215, train_loss: 13.2000, eval_loss: 12.5333\n",
      "Epoch: 216, train_loss: 13.1943, eval_loss: 12.5275\n",
      "Epoch: 217, train_loss: 13.2107, eval_loss: 12.5304\n",
      "Epoch: 218, train_loss: 13.1848, eval_loss: 12.6302\n",
      "Epoch: 219, train_loss: 13.2040, eval_loss: 12.6175\n",
      "Epoch: 220, train_loss: 13.2912, eval_loss: 12.5733\n",
      "Epoch: 221, train_loss: 13.1945, eval_loss: 12.5504\n",
      "Epoch: 222, train_loss: 13.2056, eval_loss: 12.5649\n",
      "Epoch: 223, train_loss: 13.2018, eval_loss: 12.5184\n",
      "Epoch: 224, train_loss: 13.1941, eval_loss: 12.4929\n",
      "Epoch: 225, train_loss: 13.1946, eval_loss: 12.5330\n",
      "Epoch: 226, train_loss: 13.2169, eval_loss: 12.5212\n",
      "Epoch: 227, train_loss: 13.1819, eval_loss: 12.5451\n",
      "Epoch: 228, train_loss: 13.2068, eval_loss: 12.6364\n",
      "Epoch: 229, train_loss: 13.2000, eval_loss: 12.5701\n",
      "Epoch: 230, train_loss: 13.1908, eval_loss: 12.5454\n",
      "Epoch: 231, train_loss: 13.2038, eval_loss: 12.5494\n",
      "Epoch: 232, train_loss: 13.1855, eval_loss: 12.5485\n",
      "Epoch: 233, train_loss: 13.1869, eval_loss: 12.5188\n",
      "Epoch: 234, train_loss: 13.2014, eval_loss: 12.5260\n",
      "Epoch: 235, train_loss: 13.1933, eval_loss: 12.4946\n",
      "Epoch: 236, train_loss: 13.2192, eval_loss: 12.5965\n",
      "Epoch: 237, train_loss: 13.2024, eval_loss: 12.5087\n",
      "Epoch: 238, train_loss: 13.2209, eval_loss: 12.5531\n",
      "Epoch: 239, train_loss: 13.1805, eval_loss: 12.5137\n",
      "Epoch: 240, train_loss: 13.2071, eval_loss: 12.5417\n",
      "Epoch: 241, train_loss: 13.1870, eval_loss: 12.5550\n",
      "Epoch: 242, train_loss: 13.1845, eval_loss: 12.5419\n",
      "Epoch: 243, train_loss: 13.2187, eval_loss: 12.5584\n",
      "Epoch: 244, train_loss: 13.2728, eval_loss: 12.6188\n",
      "Epoch: 245, train_loss: 13.1924, eval_loss: 12.5134\n",
      "Epoch: 246, train_loss: 13.1959, eval_loss: 12.5563\n",
      "Epoch: 247, train_loss: 13.1853, eval_loss: 12.5097\n",
      "Epoch: 248, train_loss: 13.1840, eval_loss: 12.5519\n",
      "Epoch: 249, train_loss: 13.1796, eval_loss: 12.4930\n",
      "Epoch: 250, train_loss: 13.1857, eval_loss: 12.5104\n",
      "Epoch: 251, train_loss: 13.1702, eval_loss: 12.9449\n",
      "Epoch: 252, train_loss: 13.2516, eval_loss: 12.5817\n",
      "Epoch: 253, train_loss: 13.2772, eval_loss: 12.5046\n",
      "Epoch: 254, train_loss: 13.2216, eval_loss: 12.5663\n",
      "Epoch: 255, train_loss: 13.2320, eval_loss: 12.7338\n",
      "Epoch: 256, train_loss: 13.1660, eval_loss: 12.4990\n",
      "Epoch: 257, train_loss: 13.2546, eval_loss: 12.5263\n",
      "Epoch: 258, train_loss: 13.1813, eval_loss: 12.5201\n",
      "Epoch: 259, train_loss: 13.2195, eval_loss: 12.5135\n",
      "Epoch: 260, train_loss: 13.2325, eval_loss: 12.5047\n",
      "Epoch: 261, train_loss: 13.2154, eval_loss: 12.5366\n",
      "Epoch: 262, train_loss: 13.2167, eval_loss: 12.5541\n",
      "Epoch: 263, train_loss: 13.2139, eval_loss: 12.5213\n",
      "Epoch: 264, train_loss: 13.2679, eval_loss: 12.6092\n",
      "Epoch: 265, train_loss: 13.2066, eval_loss: 12.5409\n",
      "Epoch: 266, train_loss: 13.2045, eval_loss: 12.5805\n",
      "Epoch: 267, train_loss: 13.2052, eval_loss: 12.6081\n",
      "Epoch: 268, train_loss: 13.2108, eval_loss: 12.5192\n",
      "Epoch: 269, train_loss: 13.2151, eval_loss: 12.5768\n",
      "Epoch: 270, train_loss: 13.2487, eval_loss: 12.3969\n",
      "Epoch: 271, train_loss: 13.2116, eval_loss: 12.4431\n",
      "Epoch: 272, train_loss: 13.2259, eval_loss: 12.4344\n",
      "Epoch: 273, train_loss: 13.1967, eval_loss: 12.4199\n",
      "Epoch: 274, train_loss: 13.2161, eval_loss: 12.3888\n",
      "Epoch: 275, train_loss: 13.1732, eval_loss: 12.4319\n",
      "Epoch: 276, train_loss: 13.2456, eval_loss: 12.3436\n",
      "Epoch: 277, train_loss: 13.3195, eval_loss: 12.3387\n",
      "Epoch: 278, train_loss: 13.2541, eval_loss: 12.3258\n",
      "Epoch: 279, train_loss: 13.2527, eval_loss: 12.3749\n",
      "Epoch: 280, train_loss: 13.2369, eval_loss: 12.3576\n",
      "Epoch: 281, train_loss: 13.2617, eval_loss: 12.3945\n",
      "Epoch: 282, train_loss: 13.3292, eval_loss: 12.3132\n",
      "Epoch: 283, train_loss: 13.3358, eval_loss: 12.4545\n",
      "Epoch: 284, train_loss: 13.2565, eval_loss: 12.4217\n",
      "Epoch: 285, train_loss: 13.2625, eval_loss: 12.4213\n",
      "Epoch: 286, train_loss: 13.1744, eval_loss: 12.4090\n",
      "Epoch: 287, train_loss: 13.2102, eval_loss: 12.4365\n",
      "Epoch: 288, train_loss: 13.1944, eval_loss: 12.3524\n",
      "Epoch: 289, train_loss: 13.2083, eval_loss: 12.3883\n",
      "Epoch: 290, train_loss: 13.1852, eval_loss: 12.3590\n",
      "Epoch: 291, train_loss: 13.2164, eval_loss: 12.4014\n",
      "Epoch: 292, train_loss: 13.2101, eval_loss: 12.3354\n",
      "Epoch: 293, train_loss: 13.2110, eval_loss: 12.3333\n",
      "Epoch: 294, train_loss: 13.1685, eval_loss: 12.3928\n",
      "Epoch: 295, train_loss: 13.2191, eval_loss: 12.3754\n",
      "Epoch: 296, train_loss: 13.2998, eval_loss: 12.4067\n",
      "Epoch: 297, train_loss: 13.2554, eval_loss: 12.3312\n",
      "Epoch: 298, train_loss: 13.2210, eval_loss: 12.3517\n",
      "Epoch: 299, train_loss: 13.2306, eval_loss: 12.3383\n",
      "Epoch: 300, train_loss: 13.3092, eval_loss: 12.4310\n",
      "Epoch: 301, train_loss: 13.2373, eval_loss: 12.4114\n",
      "Epoch: 302, train_loss: 13.2033, eval_loss: 12.4921\n",
      "Epoch: 303, train_loss: 13.2031, eval_loss: 12.4753\n",
      "Epoch: 304, train_loss: 13.1720, eval_loss: 12.4834\n",
      "Epoch: 305, train_loss: 13.1700, eval_loss: 12.3004\n",
      "Epoch: 306, train_loss: 13.1518, eval_loss: 12.4777\n",
      "Epoch: 307, train_loss: 13.1462, eval_loss: 12.4210\n",
      "Epoch: 308, train_loss: 13.1690, eval_loss: 12.4925\n",
      "Epoch: 309, train_loss: 13.1860, eval_loss: 12.3509\n",
      "Epoch: 310, train_loss: 13.2055, eval_loss: 12.4470\n",
      "Epoch: 311, train_loss: 13.1305, eval_loss: 12.3396\n",
      "Epoch: 312, train_loss: 13.2273, eval_loss: 12.5571\n",
      "Epoch: 313, train_loss: 13.1301, eval_loss: 12.3778\n",
      "Epoch: 314, train_loss: 13.1081, eval_loss: 12.4046\n",
      "Epoch: 315, train_loss: 13.1703, eval_loss: 12.4337\n",
      "Epoch: 316, train_loss: 13.1279, eval_loss: 12.4402\n",
      "Epoch: 317, train_loss: 13.1539, eval_loss: 12.3030\n",
      "Epoch: 318, train_loss: 13.1499, eval_loss: 12.4471\n",
      "Epoch: 319, train_loss: 13.2530, eval_loss: 12.3145\n",
      "Epoch: 320, train_loss: 13.2696, eval_loss: 12.3411\n",
      "Epoch: 321, train_loss: 13.2858, eval_loss: 12.3569\n",
      "Epoch: 322, train_loss: 13.2617, eval_loss: 12.3616\n",
      "Epoch: 323, train_loss: 13.2492, eval_loss: 12.3491\n",
      "Epoch: 324, train_loss: 13.2603, eval_loss: 12.3898\n",
      "Epoch: 325, train_loss: 13.2086, eval_loss: 12.3530\n",
      "Epoch: 326, train_loss: 13.2184, eval_loss: 12.3527\n",
      "Epoch: 327, train_loss: 13.2213, eval_loss: 12.3724\n",
      "Epoch: 328, train_loss: 13.2658, eval_loss: 12.6372\n",
      "Epoch: 329, train_loss: 13.2220, eval_loss: 12.3531\n",
      "Epoch: 330, train_loss: 13.2170, eval_loss: 12.3349\n",
      "Epoch: 331, train_loss: 13.2373, eval_loss: 12.3560\n",
      "Epoch: 332, train_loss: 13.2447, eval_loss: 12.3704\n",
      "Epoch: 333, train_loss: 13.2145, eval_loss: 12.3692\n",
      "Epoch: 334, train_loss: 13.2092, eval_loss: 12.3642\n",
      "Epoch: 335, train_loss: 13.2101, eval_loss: 12.3608\n",
      "Epoch: 336, train_loss: 13.2315, eval_loss: 12.4012\n",
      "Epoch: 337, train_loss: 13.2047, eval_loss: 12.3620\n",
      "Epoch: 338, train_loss: 13.2422, eval_loss: 12.3343\n",
      "Epoch: 339, train_loss: 13.1832, eval_loss: 12.3988\n",
      "Epoch: 340, train_loss: 13.2058, eval_loss: 12.3373\n",
      "Epoch: 341, train_loss: 13.2056, eval_loss: 12.4282\n",
      "Epoch: 342, train_loss: 13.2243, eval_loss: 12.5325\n",
      "Epoch: 343, train_loss: 13.2047, eval_loss: 12.3935\n",
      "Epoch: 344, train_loss: 13.2052, eval_loss: 12.3904\n",
      "Epoch: 345, train_loss: 13.1967, eval_loss: 12.3610\n",
      "Epoch: 346, train_loss: 13.1927, eval_loss: 12.3713\n",
      "Epoch: 347, train_loss: 13.1887, eval_loss: 12.3476\n",
      "Epoch: 348, train_loss: 13.1853, eval_loss: 12.3549\n",
      "Epoch: 349, train_loss: 13.2304, eval_loss: 12.4038\n",
      "Epoch: 350, train_loss: 13.3138, eval_loss: 12.5003\n",
      "Epoch: 351, train_loss: 13.2453, eval_loss: 12.4173\n",
      "Epoch: 352, train_loss: 13.1973, eval_loss: 12.4901\n",
      "Epoch: 353, train_loss: 13.1673, eval_loss: 12.5292\n",
      "Epoch: 354, train_loss: 13.1453, eval_loss: 12.5023\n",
      "Epoch: 355, train_loss: 13.1285, eval_loss: 12.4582\n",
      "Epoch: 356, train_loss: 13.1338, eval_loss: 12.4818\n",
      "Epoch: 357, train_loss: 13.1263, eval_loss: 12.4518\n",
      "Epoch: 358, train_loss: 13.1066, eval_loss: 12.4435\n",
      "Epoch: 359, train_loss: 13.0981, eval_loss: 12.4341\n",
      "Epoch: 360, train_loss: 13.0980, eval_loss: 12.4140\n",
      "Epoch: 361, train_loss: 13.0710, eval_loss: 12.4454\n",
      "Epoch: 362, train_loss: 13.0801, eval_loss: 12.4371\n",
      "Epoch: 363, train_loss: 13.0847, eval_loss: 12.3919\n",
      "Epoch: 364, train_loss: 13.0770, eval_loss: 12.4168\n",
      "Epoch: 365, train_loss: 13.0609, eval_loss: 12.5158\n",
      "Epoch: 366, train_loss: 13.0573, eval_loss: 12.4979\n",
      "Epoch: 367, train_loss: 13.0309, eval_loss: 12.4874\n",
      "Epoch: 368, train_loss: 13.0003, eval_loss: 12.3983\n",
      "Epoch: 369, train_loss: 13.0598, eval_loss: 12.4789\n",
      "Epoch: 370, train_loss: 13.0394, eval_loss: 12.4287\n",
      "Epoch: 371, train_loss: 13.0222, eval_loss: 12.5576\n",
      "Epoch: 372, train_loss: 13.0193, eval_loss: 12.4530\n",
      "Epoch: 373, train_loss: 13.0167, eval_loss: 12.4636\n",
      "Epoch: 374, train_loss: 13.0036, eval_loss: 12.5203\n",
      "Epoch: 375, train_loss: 13.0653, eval_loss: 12.4649\n",
      "Epoch: 376, train_loss: 13.0460, eval_loss: 12.4161\n",
      "Epoch: 377, train_loss: 13.0182, eval_loss: 12.4191\n",
      "Epoch: 378, train_loss: 13.0019, eval_loss: 12.4248\n",
      "Epoch: 379, train_loss: 13.0496, eval_loss: 12.4041\n",
      "Epoch: 380, train_loss: 13.0420, eval_loss: 12.3986\n",
      "Epoch: 381, train_loss: 13.0495, eval_loss: 12.5550\n",
      "Epoch: 382, train_loss: 13.0197, eval_loss: 12.4644\n",
      "Epoch: 383, train_loss: 12.9862, eval_loss: 12.6655\n",
      "Epoch: 384, train_loss: 13.3458, eval_loss: 12.4145\n",
      "Epoch: 385, train_loss: 12.9881, eval_loss: 12.4010\n",
      "Epoch: 386, train_loss: 13.0349, eval_loss: 12.3337\n",
      "Epoch: 387, train_loss: 13.0171, eval_loss: 12.4520\n",
      "Epoch: 388, train_loss: 13.0665, eval_loss: 12.4457\n",
      "Epoch: 389, train_loss: 13.0123, eval_loss: 12.5811\n",
      "Epoch: 390, train_loss: 13.0314, eval_loss: 12.5054\n",
      "Epoch: 391, train_loss: 12.9534, eval_loss: 12.5469\n",
      "Epoch: 392, train_loss: 13.0525, eval_loss: 12.3841\n",
      "Epoch: 393, train_loss: 12.9892, eval_loss: 12.4565\n",
      "Epoch: 394, train_loss: 12.9753, eval_loss: 12.4171\n",
      "Epoch: 395, train_loss: 12.9875, eval_loss: 12.4920\n",
      "Epoch: 396, train_loss: 12.9411, eval_loss: 12.5228\n",
      "Epoch: 397, train_loss: 13.0467, eval_loss: 12.4363\n",
      "Epoch: 398, train_loss: 13.0104, eval_loss: 12.4184\n",
      "Epoch: 399, train_loss: 13.0142, eval_loss: 12.4907\n"
     ]
    }
   ],
   "source": [
    "# fix the seed for reproducibility\n",
    "seed = args.seed\n",
    "jax.random.PRNGKey(seed)\n",
    "np.random.seed(seed)\n",
    "rng = jax.random.PRNGKey(seed)\n",
    "rng, key = jax.random.split(rng)\n",
    "\n",
    "# init the dataset\n",
    "dataset = LCSFEM_Bias_Dataset(args.pair_file, args.purple_air_dir, args.air_now_dir)\n",
    "len_test = int(len(dataset) * args.test_ratio)\n",
    "train_set, test_set = random_split(dataset, [(len(dataset) - len_test), len_test])\n",
    "print(len(train_set), len(test_set))\n",
    "print(len(dataset))\n",
    "\n",
    "\n",
    "training_generator = NumpyLoader(train_set, batch_size=args.batch_size, num_workers=0)\n",
    "testing_generator = NumpyLoader(test_set, batch_size=args.batch_size, num_workers=0)\n",
    "\n",
    "# init the model\n",
    "model = MLP([args.n_input_vars, 256, 128, 64, 1])\n",
    "\n",
    "# init train state\n",
    "init_data = jnp.ones((args.batch_size, args.n_input_vars), jnp.float32)\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=model.init(rng, init_data)['params'],\n",
    "    tx=optax.adam(args.lr),\n",
    ")\n",
    "\n",
    "# init eval state\n",
    "rng, z_key, eval_rng = jax.random.split(rng, args.n_input_vars)\n",
    "z = jax.random.normal(z_key, (64, 256))\n",
    "\n",
    "# init checkpoint dir\n",
    "ckpt_dir = 'ckpts'\n",
    "\n",
    "if os.path.exists(ckpt_dir):\n",
    "    shutil.rmtree(ckpt_dir)  # Remove any existing checkpoints from the last notebook run.\n",
    "\n",
    "# checkpoint\n",
    "config = {'batch_size': args.batch_size, 'accum_iter': args.accum_iter}\n",
    "ckpt = {'model': state, 'config': config, 'data': training_generator}\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(ckpt)\n",
    "orbax_checkpointer.save('ckpts/orbax/single_save', ckpt, save_args=save_args)\n",
    "options = orbax.checkpoint.CheckpointManagerOptions(max_to_keep=2, create=True)\n",
    "checkpoint_manager = orbax.checkpoint.CheckpointManager(\n",
    "    'ckpts/orbax/managed', orbax_checkpointer, options)\n",
    "\n",
    "if checkpoint_manager.latest_step() is not None:  # existing checkpoint present\n",
    "  # Use convenience function to construct args.\n",
    "  shardings = jax.tree_map(lambda x: x.sharding, ckpt)\n",
    "  restore_args = checkpoint_utils.construct_restore_args(\n",
    "                    ckpt, shardings)\n",
    "  # Directly construct args.\n",
    "  restore_args = jax.tree_map(\n",
    "    lambda x: ArrayRestoreArgs(\n",
    "        # Restore as object. Could also be np.ndarray, int, or others.\n",
    "        restore_type=jax.Array,\n",
    "        # Cast the restored array to a specific dtype.\n",
    "        dtype=np.float32,\n",
    "        mesh=x.sharding.mesh,\n",
    "        mesh_axes=x.sharding.spec,\n",
    "        # Padding or truncation may occur. Ensure that the shape matches the\n",
    "        # saved shape!\n",
    "        global_shape=x.shape,\n",
    "    ),\n",
    "    train_state)\n",
    "  # Note the use of plural 'items' and 'restore_kwargs'. This is because we may\n",
    "  # be managing multiple items, as shown in the previous section. It is also\n",
    "  # valid to just have one item, as shown here.\n",
    "  restored = checkpoint_manager.restore(checkpoint_manager.latest_step(), \n",
    "                items=ckpt, restore_kwargs=restore_args)\n",
    "\n",
    "# tensorboard\n",
    "summary_writer = tensorboard.SummaryWriter('logs/l2_regression')\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    # training loop\n",
    "    state, train_loss = train_one_epoch(state, training_generator)\n",
    "\n",
    "    # save checkpoint\n",
    "    checkpoint_manager.save(epoch, ckpt, save_kwargs={'save_args': save_args})\n",
    "\n",
    "    # evaluation loop\n",
    "    eval_loss = eval(state, testing_generator)\n",
    "\n",
    "    # print loss and write the tensorboard\n",
    "    print(f'Epoch: {epoch:d}, train_loss: {train_loss:.4f}, eval_loss: {eval_loss:.4f}')\n",
    "    summary_writer.scalar('train_loss', train_loss, epoch)\n",
    "    summary_writer.scalar('eval_loss', eval_loss, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843bebb-1209-4688-8a9c-0e8f7459da80",
   "metadata": {},
   "source": [
    "#### create prediction and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2186fecd-823f-4ff2-a123-f6e9c3b1f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_y_pred = jnp.array([])\n",
    "eval_y_obs = jnp.array([])\n",
    "for i, (x,y) in enumerate(testing_generator):\n",
    "    # make forward pass\n",
    "    y_hat = state.apply_fn({'params': state.params}, x)\n",
    "    eval_y_obs = jnp.concatenate([eval_y_obs, y.flatten()])\n",
    "    eval_y_pred = jnp.concatenate([eval_y_pred, y_hat.flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d57a451-e11e-4180-a119-55375fe7c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff2b2929-365d-452f-a59f-bd1e153c4f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Prediction (calibrated PM2.5)')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(eval_y_obs, eval_y_pred)\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Prediction (calibrated PM2.5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91d094ee-ab96-4f59-a2dc-8defed164c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-77cd79bfcce2eb7b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-77cd79bfcce2eb7b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eef335-36d3-4940-b3b8-ec2feca428fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
